{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset:\n",
      "['Customer No', 'post_21_july_unit', 'post_21_august_unit', 'post_21_sep_unit', 'post_21_oct_unit', 'post_21_nov_unit', 'post_21_dec_unit', 'post_22_jan_unit', 'post_22_feb_unit', 'post_22_mar_unit', 'post_22_april_unit', 'post_22_may_unit', 'pre_22_june_unit', 'pre_22_july_unit', 'pre_22_aug_unit', 'pre_22_sep_unit', 'pre_22_oct_unit', 'pre_22_nov_unit', 'pre_22_dec_unit', 'pre_23_jan_unit', 'pre_23_feb_unit', 'pre_23_mar_unit', 'pre_23_apr_unit', 'pre_23_may_unit', 'pre_23_june_unit', 'pre_23_jul_unit', 'pre_23_aug_unit', 'pre_23_sep_unit', 'pre_23_oct_unit', 'pre_23_nov_unit', 'pre_23_dec_unit', 'cmment']\n",
      "'Customer No' column found in data.\n",
      "Columns dropped: ['cmment']\n",
      "Energy columns selected: ['post_21_july_unit', 'post_21_august_unit', 'post_21_sep_unit', 'post_21_oct_unit', 'post_21_nov_unit', 'post_21_dec_unit', 'post_22_jan_unit', 'post_22_feb_unit', 'post_22_mar_unit', 'post_22_april_unit', 'post_22_may_unit', 'pre_22_june_unit', 'pre_22_july_unit', 'pre_22_aug_unit', 'pre_22_sep_unit', 'pre_22_oct_unit', 'pre_22_nov_unit', 'pre_22_dec_unit', 'pre_23_jan_unit', 'pre_23_feb_unit', 'pre_23_mar_unit', 'pre_23_apr_unit', 'pre_23_may_unit', 'pre_23_june_unit', 'pre_23_jul_unit', 'pre_23_aug_unit', 'pre_23_sep_unit', 'pre_23_oct_unit', 'pre_23_nov_unit', 'pre_23_dec_unit']\n",
      "Sliding window data has been saved to modi_data.csv\n",
      "Cleaned original data has been saved to 'original.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'dataset.csv'  # Update this path to your dataset\n",
    "data = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Print column names to verify\n",
    "print(\"Column names in the dataset:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# Update the customer identifier column name\n",
    "id_column = 'Customer No'  # Change from 'customer_id' to 'Customer No'\n",
    "\n",
    "# Check for 'Customer No' column\n",
    "if id_column in data.columns:\n",
    "    print(f\"'{id_column}' column found in data.\")\n",
    "else:\n",
    "    print(f\"'{id_column}' column not found in data.\")\n",
    "    id_column = None  # Handle accordingly if not found\n",
    "\n",
    "# Drop unwanted columns\n",
    "# Update this list with the correct column names to delete\n",
    "columns_to_delete = ['comment', 'cmment']  # Include all possible variations\n",
    "columns_present = [col for col in columns_to_delete if col in data.columns]\n",
    "if columns_present:\n",
    "    data_cleaned = data.drop(columns=columns_present)\n",
    "    print(f\"Columns dropped: {columns_present}\")\n",
    "else:\n",
    "    data_cleaned = data\n",
    "    print(\"No columns dropped.\")\n",
    "\n",
    "# Save the cleaned data\n",
    "data_cleaned.to_csv('original.csv', index=False)\n",
    "\n",
    "# Select columns that contain 'unit' and 'pre' (adjust this logic as needed)\n",
    "energy_columns = [col for col in data_cleaned.columns if 'unit' in col]\n",
    "print(f\"Energy columns selected: {energy_columns}\")\n",
    "\n",
    "# Ensure that energy_columns are not empty\n",
    "if not energy_columns:\n",
    "    raise ValueError(\"No energy columns found. Please adjust the column selection criteria.\")\n",
    "\n",
    "window_size = 4  # Adjust the window size as needed\n",
    "\n",
    "# Define the sliding window function\n",
    "def sliding_window_with_padding(df, window_size):\n",
    "    sliding_data = []\n",
    "\n",
    "    num_cols = len(df.columns)\n",
    "    column_names = []\n",
    "\n",
    "    # Create appropriate column names for the output DataFrame\n",
    "    for i in range(window_size):\n",
    "        lag = window_size - i - 1\n",
    "        column_names += [f\"{col}_t-{lag}\" for col in df.columns]\n",
    "\n",
    "    # Pad the DataFrame with NaNs at the beginning\n",
    "    padded_df = pd.DataFrame(np.nan, index=range(window_size - 1), columns=df.columns)\n",
    "    df_padded = pd.concat([padded_df, df], ignore_index=True)\n",
    "\n",
    "    # Generate the sliding windows\n",
    "    for i in range(len(df)):\n",
    "        window = df_padded.iloc[i:i + window_size].values.flatten()\n",
    "        sliding_data.append(window)\n",
    "\n",
    "    # Create the DataFrame with sliding windows\n",
    "    sliding_df = pd.DataFrame(sliding_data, columns=column_names)\n",
    "\n",
    "    return sliding_df\n",
    "\n",
    "# Apply the sliding window function\n",
    "if id_column:\n",
    "    # Process data for each customer separately\n",
    "    grouped = data_cleaned.groupby(id_column)\n",
    "    sliding_dfs = []\n",
    "    for customer_id, group in grouped:\n",
    "        group = group.reset_index(drop=True)\n",
    "        # Only keep the energy columns\n",
    "        df = group[energy_columns]\n",
    "        # Apply sliding window function\n",
    "        sliding_df = sliding_window_with_padding(df, window_size)\n",
    "        # Add 'Customer No' column\n",
    "        sliding_df[id_column] = customer_id\n",
    "        # Append to list\n",
    "        sliding_dfs.append(sliding_df)\n",
    "    # Concatenate all sliding dataframes\n",
    "    sliding_df = pd.concat(sliding_dfs, ignore_index=True)\n",
    "else:\n",
    "    # No 'Customer No', process entire data\n",
    "    df = data_cleaned[energy_columns]\n",
    "    sliding_df = sliding_window_with_padding(df, window_size)\n",
    "\n",
    "output_file = 'modi_data.csv'\n",
    "sliding_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Output messages\n",
    "print(f\"Sliding window data has been saved to {output_file}\")\n",
    "print(\"Cleaned original data has been saved to 'original.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postpaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset:\n",
      "['Customer No', 'post_21_july_unit', 'post_21_august_unit', 'post_21_sep_unit', 'post_21_oct_unit', 'post_21_nov_unit', 'post_21_dec_unit', 'post_22_jan_unit', 'post_22_feb_unit', 'post_22_mar_unit', 'post_22_april_unit', 'post_22_may_unit', 'pre_22_june_unit', 'pre_22_july_unit', 'pre_22_aug_unit', 'pre_22_sep_unit', 'pre_22_oct_unit', 'pre_22_nov_unit', 'pre_22_dec_unit', 'pre_23_jan_unit', 'pre_23_feb_unit', 'pre_23_mar_unit', 'pre_23_apr_unit', 'pre_23_may_unit', 'pre_23_june_unit', 'pre_23_jul_unit', 'pre_23_aug_unit', 'pre_23_sep_unit', 'pre_23_oct_unit', 'pre_23_nov_unit', 'pre_23_dec_unit', 'cmment']\n",
      "'Customer No' column found in data.\n",
      "Columns dropped: ['cmment']\n",
      "Energy columns selected: ['post_21_july_unit', 'post_21_august_unit', 'post_21_sep_unit', 'post_21_oct_unit', 'post_21_nov_unit', 'post_21_dec_unit', 'post_22_jan_unit', 'post_22_feb_unit', 'post_22_mar_unit', 'post_22_april_unit', 'post_22_may_unit']\n",
      "Sliding window data has been saved to post_modi_data.csv\n",
      "Cleaned original data has been saved to 'original.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'dataset.csv'  # Update this path to your dataset\n",
    "data = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Print column names to verify\n",
    "print(\"Column names in the dataset:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# Update the customer identifier column name\n",
    "id_column = 'Customer No'  # Change from 'customer_id' to 'Customer No'\n",
    "\n",
    "# Check for 'Customer No' column\n",
    "if id_column in data.columns:\n",
    "    print(f\"'{id_column}' column found in data.\")\n",
    "else:\n",
    "    print(f\"'{id_column}' column not found in data.\")\n",
    "    id_column = None  # Handle accordingly if not found\n",
    "\n",
    "# Drop unwanted columns\n",
    "# Update this list with the correct column names to delete\n",
    "columns_to_delete = ['comment', 'cmment']  # Include all possible variations\n",
    "columns_present = [col for col in columns_to_delete if col in data.columns]\n",
    "if columns_present:\n",
    "    data_cleaned = data.drop(columns=columns_present)\n",
    "    print(f\"Columns dropped: {columns_present}\")\n",
    "else:\n",
    "    data_cleaned = data\n",
    "    print(\"No columns dropped.\")\n",
    "\n",
    "# Save the cleaned data\n",
    "data_cleaned.to_csv('original.csv', index=False)\n",
    "\n",
    "# Select columns that contain 'unit' and 'pre' (adjust this logic as needed)\n",
    "energy_columns = [col for col in data_cleaned.columns if 'unit' in col and 'post' in col]\n",
    "print(f\"Energy columns selected: {energy_columns}\")\n",
    "\n",
    "# Ensure that energy_columns are not empty\n",
    "if not energy_columns:\n",
    "    raise ValueError(\"No energy columns found. Please adjust the column selection criteria.\")\n",
    "\n",
    "window_size = 4  # Adjust the window size as needed\n",
    "\n",
    "# Define the sliding window function\n",
    "def sliding_window_with_padding(df, window_size):\n",
    "    sliding_data = []\n",
    "\n",
    "    num_cols = len(df.columns)\n",
    "    column_names = []\n",
    "\n",
    "    # Create appropriate column names for the output DataFrame\n",
    "    for i in range(window_size):\n",
    "        lag = window_size - i - 1\n",
    "        column_names += [f\"{col}_t-{lag}\" for col in df.columns]\n",
    "\n",
    "    # Pad the DataFrame with NaNs at the beginning\n",
    "    padded_df = pd.DataFrame(np.nan, index=range(window_size - 1), columns=df.columns)\n",
    "    df_padded = pd.concat([padded_df, df], ignore_index=True)\n",
    "\n",
    "    # Generate the sliding windows\n",
    "    for i in range(len(df)):\n",
    "        window = df_padded.iloc[i:i + window_size].values.flatten()\n",
    "        sliding_data.append(window)\n",
    "\n",
    "    # Create the DataFrame with sliding windows\n",
    "    sliding_df = pd.DataFrame(sliding_data, columns=column_names)\n",
    "\n",
    "    return sliding_df\n",
    "\n",
    "# Apply the sliding window function\n",
    "if id_column:\n",
    "    # Process data for each customer separately\n",
    "    grouped = data_cleaned.groupby(id_column)\n",
    "    sliding_dfs = []\n",
    "    for customer_id, group in grouped:\n",
    "        group = group.reset_index(drop=True)\n",
    "        # Only keep the energy columns\n",
    "        df = group[energy_columns]\n",
    "        # Apply sliding window function\n",
    "        sliding_df = sliding_window_with_padding(df, window_size)\n",
    "        # Add 'Customer No' column\n",
    "        sliding_df[id_column] = customer_id\n",
    "        # Append to list\n",
    "        sliding_dfs.append(sliding_df)\n",
    "    # Concatenate all sliding dataframes\n",
    "    sliding_df = pd.concat(sliding_dfs, ignore_index=True)\n",
    "else:\n",
    "    # No 'Customer No', process entire data\n",
    "    df = data_cleaned[energy_columns]\n",
    "    sliding_df = sliding_window_with_padding(df, window_size)\n",
    "\n",
    "output_file = 'post_modi_data.csv'\n",
    "sliding_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Output messages\n",
    "print(f\"Sliding window data has been saved to {output_file}\")\n",
    "print(\"Cleaned original data has been saved to 'original.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset:\n",
      "['Customer No', 'post_21_july_unit', 'post_21_august_unit', 'post_21_sep_unit', 'post_21_oct_unit', 'post_21_nov_unit', 'post_21_dec_unit', 'post_22_jan_unit', 'post_22_feb_unit', 'post_22_mar_unit', 'post_22_april_unit', 'post_22_may_unit', 'pre_22_june_unit', 'pre_22_july_unit', 'pre_22_aug_unit', 'pre_22_sep_unit', 'pre_22_oct_unit', 'pre_22_nov_unit', 'pre_22_dec_unit', 'pre_23_jan_unit', 'pre_23_feb_unit', 'pre_23_mar_unit', 'pre_23_apr_unit', 'pre_23_may_unit', 'pre_23_june_unit', 'pre_23_jul_unit', 'pre_23_aug_unit', 'pre_23_sep_unit', 'pre_23_oct_unit', 'pre_23_nov_unit', 'pre_23_dec_unit', 'cmment']\n",
      "'Customer No' column found in data.\n",
      "Columns dropped: ['cmment']\n",
      "Energy columns selected: ['pre_22_june_unit', 'pre_22_july_unit', 'pre_22_aug_unit', 'pre_22_sep_unit', 'pre_22_oct_unit', 'pre_22_nov_unit', 'pre_22_dec_unit', 'pre_23_jan_unit', 'pre_23_feb_unit', 'pre_23_mar_unit', 'pre_23_apr_unit', 'pre_23_may_unit', 'pre_23_june_unit', 'pre_23_jul_unit', 'pre_23_aug_unit', 'pre_23_sep_unit', 'pre_23_oct_unit', 'pre_23_nov_unit', 'pre_23_dec_unit']\n",
      "Sliding window data has been saved to pre_modi_data.csv\n",
      "Cleaned original data has been saved to 'original.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'dataset.csv'  # Update this path to your dataset\n",
    "data = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Print column names to verify\n",
    "print(\"Column names in the dataset:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# Update the customer identifier column name\n",
    "id_column = 'Customer No'  # Change from 'customer_id' to 'Customer No'\n",
    "\n",
    "# Check for 'Customer No' column\n",
    "if id_column in data.columns:\n",
    "    print(f\"'{id_column}' column found in data.\")\n",
    "else:\n",
    "    print(f\"'{id_column}' column not found in data.\")\n",
    "    id_column = None  # Handle accordingly if not found\n",
    "\n",
    "# Drop unwanted columns\n",
    "# Update this list with the correct column names to delete\n",
    "columns_to_delete = ['comment', 'cmment']  # Include all possible variations\n",
    "columns_present = [col for col in columns_to_delete if col in data.columns]\n",
    "if columns_present:\n",
    "    data_cleaned = data.drop(columns=columns_present)\n",
    "    print(f\"Columns dropped: {columns_present}\")\n",
    "else:\n",
    "    data_cleaned = data\n",
    "    print(\"No columns dropped.\")\n",
    "\n",
    "# Save the cleaned data\n",
    "data_cleaned.to_csv('original.csv', index=False)\n",
    "\n",
    "# Select columns that contain 'unit' and 'pre' (adjust this logic as needed)\n",
    "energy_columns = [col for col in data_cleaned.columns if 'unit' in col and 'pre' in col]\n",
    "print(f\"Energy columns selected: {energy_columns}\")\n",
    "\n",
    "# Ensure that energy_columns are not empty\n",
    "if not energy_columns:\n",
    "    raise ValueError(\"No energy columns found. Please adjust the column selection criteria.\")\n",
    "\n",
    "window_size = 4  # Adjust the window size as needed\n",
    "\n",
    "# Define the sliding window function\n",
    "def sliding_window_with_padding(df, window_size):\n",
    "    sliding_data = []\n",
    "\n",
    "    num_cols = len(df.columns)\n",
    "    column_names = []\n",
    "\n",
    "    # Create appropriate column names for the output DataFrame\n",
    "    for i in range(window_size):\n",
    "        lag = window_size - i - 1\n",
    "        column_names += [f\"{col}_t-{lag}\" for col in df.columns]\n",
    "\n",
    "    # Pad the DataFrame with NaNs at the beginning\n",
    "    padded_df = pd.DataFrame(np.nan, index=range(window_size - 1), columns=df.columns)\n",
    "    df_padded = pd.concat([padded_df, df], ignore_index=True)\n",
    "\n",
    "    # Generate the sliding windows\n",
    "    for i in range(len(df)):\n",
    "        window = df_padded.iloc[i:i + window_size].values.flatten()\n",
    "        sliding_data.append(window)\n",
    "\n",
    "    # Create the DataFrame with sliding windows\n",
    "    sliding_df = pd.DataFrame(sliding_data, columns=column_names)\n",
    "\n",
    "    return sliding_df\n",
    "\n",
    "# Apply the sliding window function\n",
    "if id_column:\n",
    "    # Process data for each customer separately\n",
    "    grouped = data_cleaned.groupby(id_column)\n",
    "    sliding_dfs = []\n",
    "    for customer_id, group in grouped:\n",
    "        group = group.reset_index(drop=True)\n",
    "        # Only keep the energy columns\n",
    "        df = group[energy_columns]\n",
    "        # Apply sliding window function\n",
    "        sliding_df = sliding_window_with_padding(df, window_size)\n",
    "        # Add 'Customer No' column\n",
    "        sliding_df[id_column] = customer_id\n",
    "        # Append to list\n",
    "        sliding_dfs.append(sliding_df)\n",
    "    # Concatenate all sliding dataframes\n",
    "    sliding_df = pd.concat(sliding_dfs, ignore_index=True)\n",
    "else:\n",
    "    # No 'Customer No', process entire data\n",
    "    df = data_cleaned[energy_columns]\n",
    "    sliding_df = sliding_window_with_padding(df, window_size)\n",
    "\n",
    "output_file = 'pre_modi_data.csv'\n",
    "sliding_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Output messages\n",
    "print(f\"Sliding window data has been saved to {output_file}\")\n",
    "print(\"Cleaned original data has been saved to 'original.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
