{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the sliding window data\n",
    "file_path = r'C:\\Users\\Shadow\\Desktop\\GIT_X\\GIT_PE\\thesis\\Sliding Window\\modi_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Identify and clean non-numeric values\n",
    "# Replace problematic non-numeric values with NaN and convert to float\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Step 2: Drop rows with NaN values\n",
    "data = data.dropna()\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data.iloc[:, :-1])  # Features\n",
    "y = scaler.fit_transform(data.iloc[:, -1].values.reshape(-1, 1))  # Target\n",
    "\n",
    "# Train-Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# Define the N-Beats Block and Model\n",
    "class NBeatsBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, theta_size):\n",
    "        super(NBeatsBlock, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, theta_size)  # Only output theta_size (forecasting steps)\n",
    "        )\n",
    "        self.backcast_size = input_size\n",
    "        self.forecast_size = theta_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        theta = self.fc(x)\n",
    "        return theta  # Return only forecast\n",
    "\n",
    "class NBeatsModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, theta_size, num_blocks):\n",
    "        super(NBeatsModel, self).__init__()\n",
    "        self.blocks = nn.ModuleList([NBeatsBlock(input_size, hidden_size, theta_size) for _ in range(num_blocks)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        forecast = torch.zeros(x.shape[0], 1).to(x.device)  # Initialize forecast shape [batch_size, 1]\n",
    "        for block in self.blocks:\n",
    "            f = block(x)  # No backcast subtraction, only forecast aggregation\n",
    "            forecast = forecast + f  # Aggregate forecasts\n",
    "        return forecast\n",
    "\n",
    "# Model parameters\n",
    "input_size = X_train.shape[1]  # Number of features\n",
    "hidden_size = 256  # Hidden layer size\n",
    "theta_size = 1  # Output size for forecasting (single future value)\n",
    "num_blocks = 3  # Number of blocks in the model\n",
    "\n",
    "# Initialize the model\n",
    "model = NBeatsModel(input_size=input_size, hidden_size=hidden_size, theta_size=theta_size, num_blocks=num_blocks)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        test_loss += loss.item()\n",
    "        all_preds.extend(y_pred.cpu().numpy())\n",
    "        all_targets.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    print(f'Test Loss (MSE): {test_loss / len(test_loader):.4f}')\n",
    "\n",
    "# Calculate Evaluation Metrics\n",
    "all_preds = np.array(all_preds).flatten()\n",
    "all_targets = np.array(all_targets).flatten()\n",
    "\n",
    "mae = mean_absolute_error(all_targets, all_preds)\n",
    "mse = mean_squared_error(all_targets, all_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(all_targets, all_preds)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "print(f'R² (R-squared): {r2:.4f}')\n",
    "\n",
    "# Make predictions and save to CSV\n",
    "with torch.no_grad():\n",
    "    future_forecast = model(X_test_tensor)\n",
    "    future_forecast = scaler.inverse_transform(future_forecast.numpy())  # Inverse scale\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    forecast_df = pd.DataFrame(future_forecast, columns=[\"Forecast\"])\n",
    "\n",
    "    # Save to CSV\n",
    "    forecast_df.to_csv('future_forecast.csv', index=False)\n",
    "\n",
    "    print(f\"Predictions saved to 'future_forecast.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the sliding window data\n",
    "file_path = r'C:\\Users\\Shadow\\Desktop\\GIT_X\\GIT_PE\\thesis\\Sliding Window\\modi_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Identify and clean non-numeric values\n",
    "# Replace problematic non-numeric values with NaN and convert to float\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Step 2: Drop rows with NaN values\n",
    "data = data.dropna()\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data.iloc[:, :-1])  # Features\n",
    "y = scaler.fit_transform(data.iloc[:, -1].values.reshape(-1, 1))  # Target\n",
    "\n",
    "# Train-Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# Define the N-Beats Block and Model\n",
    "class NBeatsBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, theta_size):\n",
    "        super(NBeatsBlock, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, theta_size)  # Only output theta_size (forecasting steps)\n",
    "        )\n",
    "        self.backcast_size = input_size\n",
    "        self.forecast_size = theta_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        theta = self.fc(x)\n",
    "        return theta  # Return only forecast\n",
    "\n",
    "class NBeatsModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, theta_size, num_blocks):\n",
    "        super(NBeatsModel, self).__init__()\n",
    "        self.blocks = nn.ModuleList([NBeatsBlock(input_size, hidden_size, theta_size) for _ in range(num_blocks)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        forecast = torch.zeros(x.shape[0], 1).to(x.device)  # Initialize forecast shape [batch_size, 1]\n",
    "        for block in self.blocks:\n",
    "            f = block(x)  # No backcast subtraction, only forecast aggregation\n",
    "            forecast = forecast + f  # Aggregate forecasts\n",
    "        return forecast\n",
    "\n",
    "# Model parameters\n",
    "input_size = X_train.shape[1]  # Number of features\n",
    "hidden_size = 256  # Hidden layer size\n",
    "theta_size = 1  # Output size for forecasting (single future value)\n",
    "num_blocks = 3  # Number of blocks in the model\n",
    "\n",
    "# Initialize the model\n",
    "model = NBeatsModel(input_size=input_size, hidden_size=hidden_size, theta_size=theta_size, num_blocks=num_blocks)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    all_preds = []  \n",
    "    all_targets = []  \n",
    "    for X_batch, y_batch in test_loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        test_loss += loss.item()\n",
    "        all_preds.extend(y_pred.cpu().numpy())\n",
    "        all_targets.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    print(f'Test Loss (MSE): {test_loss / len(test_loader):.4f}')\n",
    "\n",
    "# Calculate Evaluation Metrics\n",
    "all_preds = np.array(all_preds).flatten()\n",
    "all_targets = np.array(all_targets).flatten()\n",
    "\n",
    "mae = mean_absolute_error(all_targets, all_preds)\n",
    "mse = mean_squared_error(all_targets, all_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(all_targets, all_preds)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "print(f'R² (R-squared): {r2:.4f}')\n",
    "\n",
    "# Make predictions and save to CSV\n",
    "with torch.no_grad():\n",
    "    future_forecast = model(X_test_tensor)\n",
    "    future_forecast = scaler.inverse_transform(future_forecast.numpy())  # Inverse scale\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    forecast_df = pd.DataFrame(future_forecast, columns=[\"Forecast\"])\n",
    "\n",
    "    # Save to CSV\n",
    "    forecast_df.to_csv('future_forecast.csv', index=False)\n",
    "\n",
    "    print(f\"Predictions saved to 'future_forecast.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
